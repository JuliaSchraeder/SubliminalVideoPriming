---
title: "Speech Brain Demographics"
output: html_notebook
---

## Reduce dimensionof speech features via PCA

```{r}
library(dplyr)
library(tidyverse) # to transform data
library(mediation) # to test mediation effect of BDI
library(reshape2)
library(ggplot2)
library(afex) 
library(prism)
library(cowplot)
library(CCA)
library(psych)
library(lavaan)
library(CCP) #test which correlations are significant
library(dplyr)
```

```{r}

data <- read.csv("W:/Fmri_Forschung/Allerlei/JuliaS/GitHub/SubliminalVideoPriming/data/mri_speech/speech_and_ROI_and_demographics.csv")  # Ensure the path to your dataset is correct

# Extract names of columns related to speech features using a regular expression
features <- grep("mfccs|shimmer|jitter|pitch|loudness|pause|jitter|shimmer|frequency|duration|energy|harmonic|index|rate|ratio|bandwidth|tremor|range|regression|adjective|adposition|adverb|brunets|conjunction|determiner|honore|inflected|subordinate|sentiment|sentence|noun|repetitions|pronoun|proper|verb|word|type_token", 
                 names(data), value = TRUE)


#print(features)
speech_data <- data[, features]
```

**type-token ratio (TTR)** is a measure of lexical diversity

**Brunét's Index** is another linguistic measure used to analyze textual or lexical diversity, much like the type-token ratio.
However, it is designed to be less sensitive to text length, making it more suitable for comparisons across texts of varying lengths.

```{r}

X <- data[, c(
  "loudness_mean_neg","duration_neg","pause_durations_sum_neg","pause_durations_mean_neg", "number_of_pauses_neg", "pause_rate_neg", "brunets_index_neg","positive_sentence_ratio_neg","negative_sentence_ratio_neg","pitch_mean_neg","pitch_range_neg",
  "loudness_mean_pos","duration_pos","pause_durations_sum_pos","pause_durations_mean_pos", "number_of_pauses_pos", "pause_rate_pos", "brunets_index_pos","positive_sentence_ratio_pos","negative_sentence_ratio_pos","pitch_mean_pos","pitch_range_pos"
)]

Y <- data[, c("AP_aInsula_BA13", "AP_Amygdala","AP_aSTG_BA22","AP_aSTG_BA22_2",
"AP_Caudate_nucleus","AP_Cerebellum","AP_IFG_pOp_BA44","AP_IFG_pOp_BA44_2",
"AP_IFG_pOrb_BA47","AP_IFG_pOrb_BA47_2","AP_IFG_pOrb_BA47_3","AP_IFG_pTri_BA45",
"AP_MFG_BA9","AP_MFG_BA10","AP_MTG_BA21","AP_Parahippocampal_gyrus_BA28",
"AP_pSTG_BA22","AP_pSTG_BA22_2","AP_pSTG_BA22_3","AP_Putamen","AP_SMA_BA6",
"AP_SMA_BA6_3","AP_SMG_BA40","AP_SMG_BA40_7","AP_SMG_BA40_7_2","AP_Subcallosal_gyrus_BA34",
"AP_Thalamus")]

#

#"LP_aInsula_BA13","LP_aInsula_BA13_2","LP_Caudate_nucleus","LP_Cerebellum",
#"LP_Cerebellum_2","LP_Cerebellum_3","LP_Claustrum","LP_Cuneus_BA17",
#"LP_Heschls_gyrus_BA41","LP_IFG_pOp_BA44","LP_IFG_pOp_BA44_2","LP_IFG_pOrb_BA47",
#"LP_Insula_BA13","LP_MFG_BA9","LP_MFG_BA9_2","LP_pSTG_BA22","LP_pSTG_BA22_2","LP_SMA_BA6", #"LP_SMA_BA6_2","LP_SMG_BA40","LP_SMG_BA40_2","LP_SMG_BA40_7")]

Y_scaled <- scale(Y) #brain
X_scaled <- scale(X) #Speech
```

```{r}
library(CCA)
cca_result <- cc(X_scaled, Y_scaled)
print(cca_result$cor)
```

### Interpretation of the Canonical Correlations:

1.  **Understanding the Values**:

    -   The canonical correlations represent the strength of the relationship between pairs of canonical variates (linear combinations of variables) from your `X` and `Y` datasets.

    -   **Higher values** (e.g., 0.89, 0.86, 0.83) indicate a strong relationship between the canonical variates.

    -   **Lower values** (e.g., 0.29, 0.35) suggest a weaker relationship.

2.  **General Interpretation**:

    -   **Strong Canonical Correlations (\> 0.7)**: The first few canonical correlations are relatively high, which means that there are strong linear relationships between the first few pairs of canonical variates.
        These are likely the most interpretable and meaningful pairs.

    -   **Moderate Canonical Correlations (0.5 - 0.7)**: Mid-range correlations suggest moderate relationships, which may still be meaningful but warrant closer examination.

    -   **Weak Canonical Correlations (\< 0.5)**: The lower correlations indicate weaker relationships, and these pairs of canonical variates might not contribute much to the overall relationship between the datasets.

3.  **Key Points for Interpretation**:

    -   **First Pair of Canonical Variates**: The first canonical correlation (0.893) is typically the most important, representing the strongest linear relationship between the two datasets.

    -   **Diminishing Importance**: As you move to the right in the list of canonical correlations, the importance of each subsequent pair diminishes.
        Often, only the first few pairs are of practical significance.

    -   **Number of Significant Canonical Correlations**: You might want to focus on the first few canonical correlations that are significantly different from zero.
        This can be assessed using a statistical test, such as Wilks' Lambda.

### Canonical Variates:

You can examine the canonical variates and their loadings to understand which variables in your `X` and `Y` datasets are contributing the most to the relationships:

```{r}
# Canonical variates for X
X_canonical <- cca_result$xcoef

# Canonical variates for Y
Y_canonical <- cca_result$ycoef

# View the first few rows of canonical variates
head(X_canonical)
head(Y_canonical)
```

### **Number of Canonical Correlations**:

-   The number of canonical correlations is equal to the minimum number of variables in the `X` and `Y` datasets. Since you have 16 canonical correlations, it suggests that either `X` or `Y` (or both) have at least 16 variables. If one set had fewer than 16 variables, the number of canonical correlations would be limited to that smaller number.

1.  **Canonical Variates**:

    -   Each canonical correlation corresponds to a pair of canonical variates—linear combinations of the original variables in `X` and `Y`.

    -   The first pair of canonical variates corresponds to the largest canonical correlation, representing the strongest linear relationship between the two datasets.

    -   The second pair corresponds to the second-largest correlation, and so on, with each subsequent pair representing progressively weaker relationships.

2.  **Interpreting Multiple Canonical Correlations**:

    -   **First Canonical Correlation**: This is usually the most important and strongest relationship between the datasets.
        It often captures the primary pattern of association.

    -   **Subsequent Canonical Correlations**: These capture additional patterns of association, but they are usually weaker and may explain more subtle or less pronounced relationships.

    -   **Significance Testing**: Typically, not all canonical correlations are statistically significant.
        Higher-order canonical correlations (those with smaller values) might not be significantly different from zero, meaning they don't represent meaningful relationships between the datasets.

### What to Do with the 16 Canonical Correlations:

1.  **Focus on Significant Correlations**:

    -   After performing CCA, you would normally assess which of these correlations are statistically significant.
        Often, only the first few canonical correlations are significant and meaningful for interpretation.

    -   Use a Wilks' Lambda test or similar to determine which canonical correlations are significant.

2.  **Interpret the First Few Canonical Correlations**:

    -   The first few canonical correlations (typically 1st and 2nd) usually capture the most interpretable and strongest relationships between the speech features and brain activities.

    -   For these, examine the canonical variates to see which specific variables in `X` and `Y` are driving these relationships.

3.  **Ignore Non-Significant Correlations**:

    -   If some of the canonical correlations are not significant, they can generally be ignored in the interpretation. These correlations might represent noise rather than meaningful relationships.

## Test which correlations are significant

Wilks' Lambda test

```{r}
X_canonical <- cca_result$xcoef

# Canonical variates for Y
Y_canonical <- cca_result$ycoef

# View the first few rows of canonical variates
head(X_canonical)
head(Y_canonical)
```

```{r}
# Calculate the p-values for the canonical correlations
p_values <- p.asym(cca_result$cor, nrow(X_scaled), ncol(X_scaled), ncol(Y_scaled))
print(p_values)
```

```{r}
# Extract the canonical correlations from your CCA results
canonical_correlations = cca_result$cor
print(canonical_correlations)

# Calculate Wilks' lambda for each canonical correlation
wilks_lambda = prod(1 - canonical_correlations^2)
print(wilks_lambda)

# Calculate the Chi-square statistic
n = nrow(data)  # Total number of observations
p = ncol(X_scaled)  # Number of variables in the first set
q = ncol(Y_scaled)  # Number of variables in the second set
k = length(canonical_correlations)  # Number of canonical correlations

chi_square = -((n - 1) - (p + q + 1)/2) * log(wilks_lambda)
df = p * q  # Degrees of freedom
p_value = pchisq(chi_square, df, lower.tail = FALSE)

print(paste("Chi-square:", chi_square))
print(paste("Degrees of Freedom:", df))
print(paste("P-value:", p_value))

```

```{r}
# Create a data frame to store the results
canonical_significance <- data.frame(
  Canonical_Variates = paste0(1:length(p_values$stat), " to 8"),
  Wilks_Stat = p_values$stat,
  Approx_F = p_values$approx,
  DF1 = p_values$df1,
  DF2 = p_values$df2,
  P_Value = p_values$p.value
)
write.csv(canonical_significance, file = "W:/Fmri_Forschung/Allerlei/JuliaS/GitHub/SubliminalVideoPriming/data/mri_speech/canonical_significance_results.csv", row.names = FALSE)
```

**12th to 16th cannonical**: The p-values are above 0.05, with values like p=0.12p = 0.12p=0.12, p=0.495p = 0.495p=0.495, etc., indicating these correlations are not statistically significant.

The first 9 canonical correlations are statistically significant, and these are the pairs of canonical variates that explain meaningful relationships between your speech features and brain region activities.

Focus on interpreting the canonical variates for the first few significant correlations.
Look at the canonical loadings (coefficients) to determine which variables in `X` and `Y` are contributing most to these relationships.

## Get variance explained and correlation for each Canonical

```{r}
canonical_correlations <- cca_result$cor
variance_explained <- canonical_correlations^2
canonical_table <- data.frame(
  Canonical_Variate = paste0("Canonical ", 1:length(canonical_correlations)),
  Canonical_Correlation = round(canonical_correlations, 3),
  Variance_Explained = round(variance_explained, 3)
)
write.csv(canonical_table, "W:/Fmri_Forschung/Allerlei/JuliaS/GitHub/SubliminalVideoPriming/data/mri_speech/canonical_correlations_and_variance.csv", row.names = FALSE)

```

|     |     |     |     |     |     |     |
|-----|-----|-----|-----|-----|-----|-----|
|     |     |     |     |     |     |     |
|     |     |     |     |     |     |     |
|     |     |     |     |     |     |     |
|     |     |     |     |     |     |     |
|     |     |     |     |     |     |     |
|     |     |     |     |     |     |     |
|     |     |     |     |     |     |     |
|     |     |     |     |     |     |     |
|     |     |     |     |     |     |     |
|     |     |     |     |     |     |     |
|     |     |     |     |     |     |     |
|     |     |     |     |     |     |     |
|     |     |     |     |     |     |     |

Extract canonical scores

```{r}
# 'cca_result' is the result from your CCA

# Compute canonical scores for X and Y variables
X_scores <- X_scaled %*% cca_result$xcoef
Y_scores <- Y_scaled %*% cca_result$ycoef

# Convert to data frames for easier manipulation
X_scores_df <- as.data.frame(X_scores)
Y_scores_df <- as.data.frame(Y_scores)

# Name the canonical scores for clarity (e.g., Canonical1, Canonical2, ...)
colnames(X_scores_df) <- paste0("Canonical_Speech", 1:ncol(X_scores_df))
colnames(Y_scores_df) <- paste0("Canonical_Brain", 1:ncol(Y_scores_df))

# Subset only the first six canonical variates
X_scores_df <- X_scores_df[, 1:3]
Y_scores_df <- Y_scores_df[, 1:3]
```

Interpret Canonical Loadings

```{r}
# Assuming cca_result is your object with canonical correlation analysis results
# Extract the canonical loadings for X (speech features) and Y (brain regions)
canonical_loadings_X <- cca_result$xcoef
canonical_loadings_Y <- cca_result$ycoef

# Convert to data frames for easier manipulation
canonical_loadings_X_df <- as.data.frame(canonical_loadings_X)
canonical_loadings_Y_df <- as.data.frame(canonical_loadings_Y)

# Name the columns to represent the canonical variates
colnames(canonical_loadings_X_df) <- paste0("Canonical_", 1:ncol(canonical_loadings_X_df))
colnames(canonical_loadings_Y_df) <- paste0("Canonical_", 1:ncol(canonical_loadings_Y_df))

# Add the variable names (assuming you have rownames for your speech and brain variables)
canonical_loadings_X_df$Variable <- rownames(canonical_loadings_X_df)
canonical_loadings_Y_df$Variable <- rownames(canonical_loadings_Y_df)

# Add dataset labels (Speech or Brain)
canonical_loadings_X_df$Dataset <- "Speech"
canonical_loadings_Y_df$Dataset <- "Brain"

```

```{r}
# Combine the canonical loadings for X and Y into a single data frame
canonical_loadings_combined <- data.frame(
  Variable = c(rownames(canonical_loadings_X_df), rownames(canonical_loadings_Y_df)),
  Dataset = c(rep("Speech", nrow(canonical_loadings_X_df)), rep("Brain", nrow(canonical_loadings_Y_df))),
  Canonical_1 = c(canonical_loadings_X_df[,1], canonical_loadings_Y_df[,1]),
  Canonical_2 = c(canonical_loadings_X_df[,2], canonical_loadings_Y_df[,2]),
  Canonical_3 = c(canonical_loadings_X_df[,3], canonical_loadings_Y_df[,3]),
  Canonical_4 = c(canonical_loadings_X_df[,4], canonical_loadings_Y_df[,4])
)


head(canonical_loadings_combined)
write.csv(canonical_loadings_combined,
          "W:/Fmri_Forschung/Allerlei/JuliaS/GitHub/SubliminalVideoPriming/data/mri_speech/canonical_loadings_combined.csv", row.names = FALSE)

```

Get the top loading features for the canonical

```{r}

# Load the combined canonical loadings data
canonical_data <- read_csv("W:/Fmri_Forschung/Allerlei/JuliaS/GitHub/SubliminalVideoPriming/data/mri_speech/canonical_loadings_combined.csv")

# Define the canonical variates to loop over
canonical_vars <- paste0("Canonical_", 1:3)

# Initialize empty data frame
top_contributors <- data.frame()

# Loop through each canonical variate
for (canonical_var in canonical_vars) {
  for (dataset in c("Speech", "Brain")) {
    
    # Filter for dataset and get top 3 by absolute loading
    top_vars <- canonical_data %>%
      filter(Dataset == dataset) %>%
      arrange(desc(abs(.data[[canonical_var]]))) %>%
      slice_head(n = 3) %>%
      select(Variable, Dataset, Loading = all_of(canonical_var)) %>%
      mutate(Canonical_Variate = canonical_var)
    
    # Combine with overall result
    top_contributors <- bind_rows(top_contributors, top_vars)
  }
}

# Optional: Save to CSV
write_csv(top_contributors, "W:/Fmri_Forschung/Allerlei/JuliaS/GitHub/SubliminalVideoPriming/data/mri_speech/top_contributors_first_3_canonicals.csv")

# View the top contributors
print(top_contributors)

```

Speech_Canonical_X ───► Brain_Canonical_Y

└─────────► BDI ───────┘

#### **Project the participants onto the canonical axes** (i.e., compute the scores):

```{r}
# Canonical scores = projections of participants onto canonical variates
X_scores <- X_scaled %*% cca_result$xcoef  # Speech canonical scores
Y_scores <- Y_scaled %*% cca_result$ycoef  # Brain canonical scores

```

#### **Convert to data frames and label them**:

```{r}
X_scores_df <- as.data.frame(X_scores)
Y_scores_df <- as.data.frame(Y_scores)

colnames(X_scores_df) <- paste0("Canonical_Speech", 1:ncol(X_scores_df))
colnames(Y_scores_df) <- paste0("Canonical_Brain", 1:ncol(Y_scores_df))

```

#### **Combine with participant IDs**:

```{r}
X_scores_df$id <- data$id
Y_scores_df$id <- data$id
```

#### **Merge into a single dataframe (if desired)**:

```{r}
canonical_scores <- merge(X_scores_df, Y_scores_df, by = "id")
canonical_scores
```

```{r}
# Merge canonical scores with original data to get BDI
canonical_scores_bdi <- merge(canonical_scores, data[, c("id", "BDI.II.Sum.score")], by = "id")
canonical_scores_bdi
```

```{r}
write_csv(canonical_scores_bdi, "W:/Fmri_Forschung/Allerlei/JuliaS/GitHub/SubliminalVideoPriming/data/mri_speech/canonicals_plus_BDI.csv")
```

# Mediation of BDI on CCA

```{r}
library(mediation)
```

```{r}
results_list <- list()

for (i in 1:3) {
  treat_var <- paste0("Canonical_Speech", i)
  outcome_var <- paste0("Canonical_Brain", i)
  
  model_m <- lm(as.formula(paste("BDI.II.Sum.score ~", treat_var)), data = canonical_scores_bdi)
  model_y <- lm(as.formula(paste(outcome_var, "~", treat_var, "+ BDI.II.Sum.score")), data = canonical_scores_bdi)
  
  med_result <- mediate(model.m = model_m, model.y = model_y,
                        treat = treat_var,
                        mediator = "BDI.II.Sum.score",
                        boot = TRUE, sims = 1000)
  
  cat("\n=======================\n")
  cat(paste("Canonical", i, "\n"))
  print(summary(med_result))
  
  results_list[[i]] <- med_result
}

```

| Term | What it Means |
|----|----|
| **ACME** | *Average Causal Mediation Effect* → the **indirect effect** (Speech → BDI → Brain) |
| **ADE** | *Average Direct Effect* → direct path (Speech → Brain, not through BDI) |
| **Total Effect** | ACME + ADE = total impact of Speech on Brain |
| **Prop. Mediated** | How much of the total effect is mediated through BDI |
