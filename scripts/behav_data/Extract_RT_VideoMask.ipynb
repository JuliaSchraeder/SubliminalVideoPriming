{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to exctract mean reaction time\n",
    "----\n",
    "- for all 12 timing conditions and all 7 main effects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules \n",
    "import pandas as pd\n",
    "import ast, os\n",
    "import numpy as np\n",
    "import csv\n",
    "import fileinput\n",
    "import glob\n",
    "from numpy import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RT of all trials\n",
    "def total_mean_rt(csvfile, vp_number):\n",
    "    rt = reaction_time.dropna()\n",
    "    total_mean_rt = sum(rt)/len(rt)\n",
    "    \n",
    "    return total_mean_rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many answere where correct? in total\n",
    "def number_corr_ans(csvfile, vp_number):                        \n",
    "    number_corr_ans_nonformatted = sum(corr_answers) \n",
    "    number_corr_ans = \"{:.0f}\".format(number_corr_ans_nonformatted)    # format value to not show .0\n",
    "    \n",
    "    return number_corr_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How often was a key pressed?\n",
    "def reaction_number(csvfile, vp_number):\n",
    "    pure_reaction_time = reaction_time.dropna()                        # delete trials without answer\n",
    "    reaction_number = len(pure_reaction_time)                          # number of reactions without missing values\n",
    "    \n",
    "    return reaction_number    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean rt\n",
    "\n",
    "def rt_incongruent(csvfile,vp_number):\n",
    "    a = incongruent['key_resp.rt']\n",
    "    b = a.dropna()\n",
    "    \n",
    "    # If len corr ans = Zero:\n",
    "    if len(b) != 0:\n",
    "        rt_incongruent = sum(b)/len(b)\n",
    "    else:\n",
    "        rt_incongruent = 0\n",
    "\n",
    "    return rt_incongruent\n",
    "\n",
    "def rt_congruent(csvfile,vp_number):\n",
    "    a = congruent['key_resp.rt']\n",
    "    b = a.dropna()\n",
    "    rt_congruent = sum(b)/len(b)\n",
    "    \n",
    "    return rt_congruent\n",
    "\n",
    "def rt_happy_happy(csvfile, vp_number):\n",
    "    a = happy_happy['key_resp.rt'] #get RT of happy_happy  trials\n",
    "    b = a.dropna() # delete trials without answer\n",
    "    \n",
    "        # If len corr ans = Zero:\n",
    "    if len(b) != 0:\n",
    "        rt_happy_happy= sum(b)/len(b) #get mean\n",
    "    else:\n",
    "        rt_happy_happy = 0\n",
    "    \n",
    "    return rt_happy_happy\n",
    "\n",
    "def rt_happy_sad(csvfile, vp_number):\n",
    "    a = happy_sad['key_resp.rt']\n",
    "    b = a.dropna()\n",
    "    \n",
    "    # If len corr ans = Zero:\n",
    "    if len(b) != 0:\n",
    "        rt_happy_sad= sum(b)/len(b)\n",
    "    else:\n",
    "        rt_happy_sad = 0\n",
    "    \n",
    "    return rt_happy_sad\n",
    "\n",
    "\n",
    "def rt_sad_happy(csvfile, vp_number):\n",
    "    a = sad_happy['key_resp.rt']\n",
    "    b = a.dropna()\n",
    "    \n",
    "    # If len corr ans = Zero:\n",
    "    if len(b) != 0:\n",
    "        rt_sad_happy = sum(b)/len(b)\n",
    "    else:\n",
    "        rt_sad_happy = 0\n",
    "    \n",
    "    return rt_sad_happy\n",
    "\n",
    "\n",
    "def rt_sad_sad(csvfile, vp_number):\n",
    "    a = sad_sad['key_resp.rt']\n",
    "    b = a.dropna()\n",
    "    \n",
    "    # If len corr ans = Zero:\n",
    "    if len(b) != 0:\n",
    "        rt_sad_sad = sum(b)/len(b)\n",
    "    else:\n",
    "        rt_sad_sad = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    return rt_sad_sad\n",
    "\n",
    "\n",
    "# Slider\n",
    "def slider_incongruent(csvfile,vp_number):\n",
    "    slider_incongruent = incongruent['Rating'].dropna()\n",
    "    slider_incongruent = sum(slider_incongruent)/len(slider_incongruent)\n",
    "    return slider_incongruent\n",
    "\n",
    "def slider_congruent(csvfile,vp_number):\n",
    "    slider_congruent = congruent['Rating'].dropna()\n",
    "    slider_congruent = sum(slider_congruent)/len(slider_congruent)\n",
    "    return slider_congruent\n",
    "\n",
    "def slider_happy_happy(csvfile,vp_number):\n",
    "    slider_happy_happy = happy_happy['Rating'].dropna()\n",
    "    slider_happy_happy = sum(slider_happy_happy)/len(slider_happy_happy)\n",
    "    return slider_happy_happy\n",
    "\n",
    "def slider_happy_sad(csvfile,vp_number):\n",
    "    slider_happy_sad = happy_sad['Rating'].dropna()\n",
    "    slider_happy_sad = sum(slider_happy_sad)/len(slider_happy_sad)\n",
    "    return slider_happy_sad\n",
    "\n",
    "def slider_sad_sad(csvfile,vp_number):\n",
    "    slider_sad_sad = sad_sad['Rating'].dropna()\n",
    "    slider_sad_sad = sum(slider_sad_sad)/len(slider_sad_sad)\n",
    "    return slider_sad_sad\n",
    "\n",
    "def slider_sad_happy(csvfile,vp_number):\n",
    "    slider_sad_happy = sad_happy['Rating'].dropna()\n",
    "    slider_sad_happy = sum(slider_sad_happy)/len(slider_sad_happy)\n",
    "    return slider_sad_happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in csv data generated by PsychoPy\n",
    "\n",
    "participant = glob.glob('W:/Fmri_Forschung/Allerlei/JuliaS/GitHub/SubliminalVideoPriming/data/behav_data/*.csv') \n",
    "len(participant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists to append values and to store them in the dataframe df with mean reactions\n",
    "list_rt_happy_happy = []\n",
    "list_rt_happy_sad = []\n",
    "list_rt_sad_happy = []\n",
    "list_rt_sad_sad = []\n",
    "\n",
    "list_rt_incongruent = []\n",
    "list_rt_congruent = []\n",
    "\n",
    "list_slider_happy_happy = []\n",
    "list_slider_happy_sad = []\n",
    "list_slider_sad_happy = []\n",
    "list_slider_sad_sad = []\n",
    "\n",
    "list_slider_incongruent = []\n",
    "list_slider_congruent = []\n",
    "\n",
    "list_total_mean_rt= []\n",
    "list_participant_ID = []\n",
    "list_number_corr_ans = []\n",
    "list_reaction_number =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-5eb26f49912d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparticipant\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m#read in csv for every participant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mcsvfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m\";\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#delete first two rows for example trials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juhoffmann\\Anaconda3\\envs\\Bids\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juhoffmann\\Anaconda3\\envs\\Bids\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juhoffmann\\Anaconda3\\envs\\Bids\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1702\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1703\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1704\u001b[1;33m                 \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m  \u001b[1;31m# type: ignore[attr-defined]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1705\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1706\u001b[0m                 )\n",
      "\u001b[1;32mc:\\Users\\juhoffmann\\Anaconda3\\envs\\Bids\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m                 \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m                 \u001b[1;31m# destructive to chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juhoffmann\\Anaconda3\\envs\\Bids\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juhoffmann\\Anaconda3\\envs\\Bids\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juhoffmann\\Anaconda3\\envs\\Bids\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juhoffmann\\Anaconda3\\envs\\Bids\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juhoffmann\\Anaconda3\\envs\\Bids\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
     ]
    }
   ],
   "source": [
    "for i in participant:\n",
    "    #read in csv for every participant\n",
    "    csvfile = pd.read_csv(i, sep =\";\")\n",
    "        \n",
    "    #delete first two rows for example trials \n",
    "    csvfile = csvfile.iloc[2:]\n",
    "    #insert index of trials for study part starting with 0\n",
    "    length = len(csvfile)\n",
    "    csvfile.insert(loc=0, column='index', value=np.arange(length))\n",
    "    \n",
    "    #get correct trials\n",
    "    def correctness(csvfile):\n",
    "        if csvfile['corrAnsTar'] == 7 and csvfile['key_resp.keys']== \"7\":\n",
    "            return 1\n",
    "        if csvfile['corrAnsTar'] == 8 and csvfile['key_resp.keys']== \"8\":\n",
    "            return 1\n",
    "        if csvfile['corrAnsTar'] == 9 and csvfile['key_resp.keys']== \"9\":\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    csvfile['correct'] = csvfile.apply(correctness, axis=1)    \n",
    "    \n",
    "     #get correct answers\n",
    "    corr_answers = csvfile['correct']\n",
    "    #get reaction times\n",
    "    reaction_time = csvfile['key_resp.rt']\n",
    "    \n",
    "    #Get csv file for every Condition\n",
    "    happy_happy = csvfile[(csvfile['primeEmotion'] == 'happy') & (csvfile['targetEmotion'] == 'happy')]\n",
    "    happy_sad = csvfile[(csvfile['primeEmotion'] == 'happy') & (csvfile['targetEmotion'] == 'sad')]\n",
    "    sad_happy = csvfile[(csvfile['primeEmotion'] == 'sad') & (csvfile['targetEmotion'] == 'happy')]\n",
    "    sad_sad = csvfile[(csvfile['primeEmotion'] == 'sad') & (csvfile['targetEmotion'] == 'happy')]\n",
    "\n",
    "    incongruent = csvfile[csvfile['targetEmotion'] != csvfile['primeEmotion']]\n",
    "    congruent = csvfile[csvfile['targetEmotion'] == csvfile['primeEmotion']]\n",
    "\n",
    "    \n",
    "    #Excecute functions and get one value for each participant\n",
    "    val_rt_happy_happy = rt_happy_happy(csvfile,i)\n",
    "    val_rt_happy_sad = rt_happy_sad(csvfile,i)\n",
    "    val_rt_sad_happy = rt_sad_happy(csvfile,i)\n",
    "    val_rt_sad_sad = rt_sad_sad(csvfile,i)\n",
    "    val_rt_incongruent = rt_incongruent(csvfile,i)\n",
    "    val_rt_congruent = rt_congruent(csvfile,i)\n",
    "\n",
    "    val_rt_incongruent = rt_incongruent(csvfile,i)\n",
    "    val_rt_congruent = rt_congruent(csvfile,i)\n",
    "\n",
    "    val_slider_happy_happy = slider_happy_happy(csvfile,i)\n",
    "    val_slider_happy_sad = slider_happy_sad(csvfile,i)\n",
    "    val_slider_sad_happy = slider_sad_happy(csvfile,i)\n",
    "    val_slider_sad_sad = slider_sad_sad(csvfile,i)\n",
    "\n",
    "\n",
    "    val_slider_incongruent = slider_incongruent(csvfile,i)\n",
    "    val_slider_congruent = slider_congruent(csvfile,i)\n",
    "    \n",
    "    val_participant_ID = i[85:92] #get sub number of participant\n",
    "    val_number_corr_ans = number_corr_ans(csvfile,i)\n",
    "    val_reaction_number = reaction_number(csvfile,i)\n",
    "    val_total_mean_rt = total_mean_rt(csvfile,i)\n",
    "    \n",
    "    #append values to append individual value to one lis.append(val_)\n",
    "    list_rt_happy_happy.append(val_rt_happy_happy)\n",
    "    list_rt_happy_sad.append(val_rt_happy_sad)\n",
    "    list_rt_sad_happy.append(val_rt_sad_happy)\n",
    "    list_rt_sad_sad.append(val_rt_sad_sad)\n",
    "    list_rt_incongruent.append(val_rt_incongruent)\n",
    "    list_rt_congruent.append(val_rt_congruent)\n",
    "    \n",
    "    list_slider_happy_happy.append(val_slider_happy_happy)\n",
    "    list_slider_happy_sad.append(val_slider_happy_sad)\n",
    "    list_slider_sad_happy.append(val_slider_sad_happy)\n",
    "    list_slider_sad_sad.append(val_slider_sad_sad)\n",
    "    list_slider_incongruent.append(val_slider_incongruent)\n",
    "    list_slider_congruent.append(val_slider_congruent)\n",
    "    \n",
    "    list_total_mean_rt.append(val_total_mean_rt)\n",
    "    list_participant_ID.append(val_participant_ID)\n",
    "    list_number_corr_ans.append(val_number_corr_ans)\n",
    "    list_reaction_number.append(val_reaction_number)\n",
    "    \n",
    "    #Create dataframe \n",
    "    rt_data = {'name': list_participant_ID,\n",
    "                     'number of reactions': list_reaction_number,\n",
    "                     'number of correct answers': list_number_corr_ans,\n",
    "                     'total trials': list_total_mean_rt,\n",
    "                     'rt_incongruent': list_rt_incongruent,\n",
    "                     'rt_congruent': list_rt_congruent,\n",
    "                     'rt_happy_happy':list_rt_happy_happy,\n",
    "                     'rt_happy_sad':list_rt_happy_sad,\n",
    "                     'rt_sad_happy':list_rt_sad_happy,\n",
    "                     'rt_sad_sad':list_rt_sad_sad,\n",
    "               \n",
    "                     'slider_incongruent': list_slider_incongruent,\n",
    "                     'slider_congruent': list_slider_congruent,\n",
    "                     'slider_happy_happy':list_slider_happy_happy,\n",
    "                     'slider_happy_sad':list_slider_happy_sad,\n",
    "                     'slider_sad_happy':list_slider_sad_happy,\n",
    "                     'slider_sad_sad':list_slider_sad_sad}\n",
    "    \n",
    "    mean_rt = pd.DataFrame(data=rt_data)\n",
    "    mean_rt = mean_rt.round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>primePerson</th>\n",
       "      <th>primeGender</th>\n",
       "      <th>prime</th>\n",
       "      <th>primeEmotion</th>\n",
       "      <th>corrAnsPrime</th>\n",
       "      <th>target</th>\n",
       "      <th>targetEmotion</th>\n",
       "      <th>corrAnsTar</th>\n",
       "      <th>Cond</th>\n",
       "      <th>...</th>\n",
       "      <th>slider_resp_study.stopped</th>\n",
       "      <th>text_ende.started</th>\n",
       "      <th>text_ende.stopped</th>\n",
       "      <th>participant</th>\n",
       "      <th>date</th>\n",
       "      <th>expName</th>\n",
       "      <th>psychopyVersion</th>\n",
       "      <th>frameRate</th>\n",
       "      <th>Unnamed: 71</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>m</td>\n",
       "      <td>033_o_m_s_a.jpg</td>\n",
       "      <td>sad</td>\n",
       "      <td>7.0</td>\n",
       "      <td>sad_94.2ns.avi</td>\n",
       "      <td>sad</td>\n",
       "      <td>7.0</td>\n",
       "      <td>congruent</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S10802</td>\n",
       "      <td>2021_Aug_05_1725</td>\n",
       "      <td>VideoMask</td>\n",
       "      <td>2021.1.2</td>\n",
       "      <td>120.101943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>f</td>\n",
       "      <td>030_o_f_s_a.jpg</td>\n",
       "      <td>sad</td>\n",
       "      <td>7.0</td>\n",
       "      <td>sad_68.1ns.avi</td>\n",
       "      <td>sad</td>\n",
       "      <td>7.0</td>\n",
       "      <td>congruent</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S10802</td>\n",
       "      <td>2021_Aug_05_1725</td>\n",
       "      <td>VideoMask</td>\n",
       "      <td>2021.1.2</td>\n",
       "      <td>120.101943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>m</td>\n",
       "      <td>008_y_m_h_a.jpg</td>\n",
       "      <td>happy</td>\n",
       "      <td>9.0</td>\n",
       "      <td>happy_26.1ns.avi</td>\n",
       "      <td>happy</td>\n",
       "      <td>9.0</td>\n",
       "      <td>congruent</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S10802</td>\n",
       "      <td>2021_Aug_05_1725</td>\n",
       "      <td>VideoMask</td>\n",
       "      <td>2021.1.2</td>\n",
       "      <td>120.101943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>f</td>\n",
       "      <td>030_o_f_s_a.jpg</td>\n",
       "      <td>sad</td>\n",
       "      <td>7.0</td>\n",
       "      <td>happy_125.3.wmv</td>\n",
       "      <td>happy</td>\n",
       "      <td>9.0</td>\n",
       "      <td>incongruent</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S10802</td>\n",
       "      <td>2021_Aug_05_1725</td>\n",
       "      <td>VideoMask</td>\n",
       "      <td>2021.1.2</td>\n",
       "      <td>120.101943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>f</td>\n",
       "      <td>021_o_f_s_a.jpg</td>\n",
       "      <td>sad</td>\n",
       "      <td>7.0</td>\n",
       "      <td>sad_9.5ns.avi</td>\n",
       "      <td>sad</td>\n",
       "      <td>7.0</td>\n",
       "      <td>congruent</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S10802</td>\n",
       "      <td>2021_Aug_05_1725</td>\n",
       "      <td>VideoMask</td>\n",
       "      <td>2021.1.2</td>\n",
       "      <td>120.101943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>56</td>\n",
       "      <td>3.0</td>\n",
       "      <td>m</td>\n",
       "      <td>013_y_m_s_a.jpg</td>\n",
       "      <td>sad</td>\n",
       "      <td>7.0</td>\n",
       "      <td>sad_7.7ns.avi</td>\n",
       "      <td>sad</td>\n",
       "      <td>7.0</td>\n",
       "      <td>congruent</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S10802</td>\n",
       "      <td>2021_Aug_05_1725</td>\n",
       "      <td>VideoMask</td>\n",
       "      <td>2021.1.2</td>\n",
       "      <td>120.101943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>57</td>\n",
       "      <td>3.0</td>\n",
       "      <td>m</td>\n",
       "      <td>013_y_m_h_a.jpg</td>\n",
       "      <td>happy</td>\n",
       "      <td>9.0</td>\n",
       "      <td>sad_113.2.wmv</td>\n",
       "      <td>sad</td>\n",
       "      <td>7.0</td>\n",
       "      <td>incongruent</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S10802</td>\n",
       "      <td>2021_Aug_05_1725</td>\n",
       "      <td>VideoMask</td>\n",
       "      <td>2021.1.2</td>\n",
       "      <td>120.101943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>58</td>\n",
       "      <td>4.0</td>\n",
       "      <td>m</td>\n",
       "      <td>004_o_m_h_a.jpg</td>\n",
       "      <td>happy</td>\n",
       "      <td>9.0</td>\n",
       "      <td>happy_25.1ns.avi</td>\n",
       "      <td>happy</td>\n",
       "      <td>9.0</td>\n",
       "      <td>congruent</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S10802</td>\n",
       "      <td>2021_Aug_05_1725</td>\n",
       "      <td>VideoMask</td>\n",
       "      <td>2021.1.2</td>\n",
       "      <td>120.101943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>f</td>\n",
       "      <td>030_o_f_h_a.jpg</td>\n",
       "      <td>happy</td>\n",
       "      <td>9.0</td>\n",
       "      <td>sad_127.1.wmv</td>\n",
       "      <td>sad</td>\n",
       "      <td>7.0</td>\n",
       "      <td>incongruent</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S10802</td>\n",
       "      <td>2021_Aug_05_1725</td>\n",
       "      <td>VideoMask</td>\n",
       "      <td>2021.1.2</td>\n",
       "      <td>120.101943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>783.834376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  primePerson primeGender            prime primeEmotion  \\\n",
       "2       0          3.0           m  033_o_m_s_a.jpg          sad   \n",
       "3       1          0.0           f  030_o_f_s_a.jpg          sad   \n",
       "4       2          8.0           m  008_y_m_h_a.jpg        happy   \n",
       "5       3          0.0           f  030_o_f_s_a.jpg          sad   \n",
       "6       4          1.0           f  021_o_f_s_a.jpg          sad   \n",
       "..    ...          ...         ...              ...          ...   \n",
       "58     56          3.0           m  013_y_m_s_a.jpg          sad   \n",
       "59     57          3.0           m  013_y_m_h_a.jpg        happy   \n",
       "60     58          4.0           m  004_o_m_h_a.jpg        happy   \n",
       "61     59          0.0           f  030_o_f_h_a.jpg        happy   \n",
       "62     60          NaN         NaN              NaN          NaN   \n",
       "\n",
       "    corrAnsPrime            target targetEmotion  corrAnsTar         Cond  \\\n",
       "2            7.0    sad_94.2ns.avi           sad         7.0    congruent   \n",
       "3            7.0    sad_68.1ns.avi           sad         7.0    congruent   \n",
       "4            9.0  happy_26.1ns.avi         happy         9.0    congruent   \n",
       "5            7.0   happy_125.3.wmv         happy         9.0  incongruent   \n",
       "6            7.0     sad_9.5ns.avi           sad         7.0    congruent   \n",
       "..           ...               ...           ...         ...          ...   \n",
       "58           7.0     sad_7.7ns.avi           sad         7.0    congruent   \n",
       "59           9.0     sad_113.2.wmv           sad         7.0  incongruent   \n",
       "60           9.0  happy_25.1ns.avi         happy         9.0    congruent   \n",
       "61           9.0     sad_127.1.wmv           sad         7.0  incongruent   \n",
       "62           NaN               NaN           NaN         NaN          NaN   \n",
       "\n",
       "    ...  slider_resp_study.stopped  text_ende.started  text_ende.stopped  \\\n",
       "2   ...                        NaN                NaN                NaN   \n",
       "3   ...                        NaN                NaN                NaN   \n",
       "4   ...                        NaN                NaN                NaN   \n",
       "5   ...                        NaN                NaN                NaN   \n",
       "6   ...                        NaN                NaN                NaN   \n",
       "..  ...                        ...                ...                ...   \n",
       "58  ...                        NaN                NaN                NaN   \n",
       "59  ...                        NaN                NaN                NaN   \n",
       "60  ...                        NaN                NaN                NaN   \n",
       "61  ...                        NaN                NaN                NaN   \n",
       "62  ...                        NaN         783.834376                NaN   \n",
       "\n",
       "    participant              date    expName  psychopyVersion   frameRate  \\\n",
       "2        S10802  2021_Aug_05_1725  VideoMask         2021.1.2  120.101943   \n",
       "3        S10802  2021_Aug_05_1725  VideoMask         2021.1.2  120.101943   \n",
       "4        S10802  2021_Aug_05_1725  VideoMask         2021.1.2  120.101943   \n",
       "5        S10802  2021_Aug_05_1725  VideoMask         2021.1.2  120.101943   \n",
       "6        S10802  2021_Aug_05_1725  VideoMask         2021.1.2  120.101943   \n",
       "..          ...               ...        ...              ...         ...   \n",
       "58       S10802  2021_Aug_05_1725  VideoMask         2021.1.2  120.101943   \n",
       "59       S10802  2021_Aug_05_1725  VideoMask         2021.1.2  120.101943   \n",
       "60       S10802  2021_Aug_05_1725  VideoMask         2021.1.2  120.101943   \n",
       "61       S10802  2021_Aug_05_1725  VideoMask         2021.1.2  120.101943   \n",
       "62          NaN               NaN        NaN              NaN         NaN   \n",
       "\n",
       "    Unnamed: 71  correct  \n",
       "2           NaN        0  \n",
       "3           NaN        0  \n",
       "4           NaN        0  \n",
       "5           NaN        0  \n",
       "6           NaN        0  \n",
       "..          ...      ...  \n",
       "58          NaN        0  \n",
       "59          NaN        0  \n",
       "60          NaN        0  \n",
       "61          NaN        0  \n",
       "62          NaN        0  \n",
       "\n",
       "[61 rows x 74 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_rt.to_csv(r'C:/Users/juhoffmann/OneDrive - Uniklinik RWTH Aachen/Auswertung/data_behav/BackwardMask_Mean_Accuracy.csv',sep =';', index = True)     \n",
    "\n",
    "mean_rt.to_csv(r'/Users/julia/OneDrive - Uniklinik RWTH Aachen/Auswertung/data_behav/VideoMask_Mean_RT_Slider.csv',sep =';', index = True)     \n",
    "#mean_rt.to_csv(r'/Users/julia/OneDrive - Uniklinik RWTH Aachen/Hauptstudie/Data/data_behav/BackwardMask_Mean_RT.csv',sep =';', index = True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rt['happy_neutral_unconscious']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bids",
   "language": "python",
   "name": "bids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
