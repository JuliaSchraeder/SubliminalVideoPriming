{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to exctract mean reaction time\n",
    "----\n",
    "- for all 12 timing conditions and all 7 main effects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules \n",
    "import pandas as pd\n",
    "import ast, os\n",
    "import numpy as np\n",
    "import csv\n",
    "import fileinput\n",
    "import glob\n",
    "from numpy import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RT of all trials\n",
    "def total_mean_rt(csvfile, vp_number):\n",
    "    rt = reaction_time.dropna()\n",
    "    total_mean_rt = sum(rt)/len(rt)\n",
    "    \n",
    "    return total_mean_rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many answere where correct? in total\n",
    "def number_corr_ans(csvfile, vp_number):                        \n",
    "    number_corr_ans_nonformatted = sum(corr_answers) \n",
    "    number_corr_ans = \"{:.0f}\".format(number_corr_ans_nonformatted)    # format value to not show .0\n",
    "    \n",
    "    return number_corr_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How often was a key pressed?\n",
    "def reaction_number(csvfile, vp_number):\n",
    "    pure_reaction_time = reaction_time.dropna()                        # delete trials without answer\n",
    "    reaction_number = len(pure_reaction_time)                          # number of reactions without missing values\n",
    "    \n",
    "    return reaction_number    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean rt\n",
    "\n",
    "def rt_incongruent(csvfile,vp_number):\n",
    "    a = incongruent['key_resp.rt']\n",
    "    b = a.dropna()\n",
    "    \n",
    "    # If len corr ans = Zero:\n",
    "    if len(b) != 0:\n",
    "        rt_incongruent = sum(b)/len(b)\n",
    "    else:\n",
    "        rt_incongruent = 0\n",
    "\n",
    "    return rt_incongruent\n",
    "\n",
    "def rt_congruent(csvfile,vp_number):\n",
    "    a = congruent['key_resp.rt']\n",
    "    b = a.dropna()\n",
    "    rt_congruent = sum(b)/len(b)\n",
    "    \n",
    "    return rt_congruent\n",
    "\n",
    "def rt_happy_happy(csvfile, vp_number):\n",
    "    a = happy_happy['key_resp.rt'] #get RT of happy_happy  trials\n",
    "    b = a.dropna() # delete trials without answer\n",
    "    \n",
    "        # If len corr ans = Zero:\n",
    "    if len(b) != 0:\n",
    "        rt_happy_happy= sum(b)/len(b) #get mean\n",
    "    else:\n",
    "        rt_happy_happy = 0\n",
    "    \n",
    "    return rt_happy_happy\n",
    "\n",
    "def rt_happy_sad(csvfile, vp_number):\n",
    "    a = happy_sad['key_resp.rt']\n",
    "    b = a.dropna()\n",
    "    \n",
    "    # If len corr ans = Zero:\n",
    "    if len(b) != 0:\n",
    "        rt_happy_sad= sum(b)/len(b)\n",
    "    else:\n",
    "        rt_happy_sad = 0\n",
    "    \n",
    "    return rt_happy_sad\n",
    "\n",
    "\n",
    "def rt_sad_happy(csvfile, vp_number):\n",
    "    a = sad_happy['key_resp.rt']\n",
    "    b = a.dropna()\n",
    "    \n",
    "    # If len corr ans = Zero:\n",
    "    if len(b) != 0:\n",
    "        rt_sad_happy = sum(b)/len(b)\n",
    "    else:\n",
    "        rt_sad_happy = 0\n",
    "    return rt_sad_happy\n",
    "\n",
    "\n",
    "def rt_sad_sad(csvfile, vp_number):\n",
    "    a = sad_sad['key_resp.rt']\n",
    "    b = a.dropna()\n",
    "    \n",
    "    # If len corr ans = Zero:\n",
    "    if len(b) != 0:\n",
    "        rt_sad_sad = sum(b)/len(b)\n",
    "    else:\n",
    "        rt_sad_sad = 0\n",
    "    return rt_sad_sad\n",
    "\n",
    "\n",
    "# Slider\n",
    "def slider_incongruent(csvfile,vp_number):\n",
    "    slider_incongruent = incongruent['Rating'].dropna()\n",
    "    slider_incongruent = sum(slider_incongruent)/len(slider_incongruent)\n",
    "    return slider_incongruent\n",
    "\n",
    "def slider_congruent(csvfile,vp_number):\n",
    "    slider_congruent = congruent['Rating'].dropna()\n",
    "    slider_congruent = sum(slider_congruent)/len(slider_congruent)\n",
    "    return slider_congruent\n",
    "\n",
    "def slider_happy_happy(csvfile,vp_number):\n",
    "    slider_happy_happy = happy_happy['Rating'].dropna()\n",
    "    slider_happy_happy = sum(slider_happy_happy)/len(slider_happy_happy)\n",
    "    return slider_happy_happy\n",
    "\n",
    "def slider_happy_sad(csvfile,vp_number):\n",
    "    slider_happy_sad = happy_sad['Rating'].dropna()\n",
    "    slider_happy_sad = sum(slider_happy_sad)/len(slider_happy_sad)\n",
    "    return slider_happy_sad\n",
    "\n",
    "def slider_sad_sad(csvfile,vp_number):\n",
    "    slider_sad_sad = sad_sad['Rating'].dropna()\n",
    "    slider_sad_sad = sum(slider_sad_sad)/len(slider_sad_sad)\n",
    "    return slider_sad_sad\n",
    "\n",
    "def slider_sad_happy(csvfile,vp_number):\n",
    "    slider_sad_happy = sad_happy['Rating'].dropna()\n",
    "    slider_sad_happy = sum(slider_sad_happy)/len(slider_sad_happy)\n",
    "    return slider_sad_happy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #read in csv for every participant\n",
    "    csvfile = pd.read_csv('W:/Fmri_Forschung/Allerlei/JuliaS/GitHub/SubliminalVideoPriming/data/behav_data/Sub-011_VideoMask_2021_Jul_23_1156_1.csv', sep =\";\")\n",
    "        \n",
    "    #delete first two rows for example trials \n",
    "    csvfile = csvfile.iloc[2:]\n",
    "    #insert index of trials for study part starting with 0\n",
    "    length = len(csvfile)\n",
    "    csvfile.insert(loc=0, column='index', value=np.arange(length))\n",
    "    \n",
    "    #get correct trials\n",
    "    def correctness(csvfile):\n",
    "        if csvfile['corrAnsTar'] == 7 and csvfile['key_resp.keys']== \"7\":\n",
    "            return 1\n",
    "        if csvfile['corrAnsTar'] == 8 and csvfile['key_resp.keys']== \"8\":\n",
    "            return 1\n",
    "        if csvfile['corrAnsTar'] == 9 and csvfile['key_resp.keys']== \"9\":\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    csvfile['correct'] = csvfile.apply(correctness, axis=1)    \n",
    "    \n",
    "     #get correct answers\n",
    "    corr_answers = csvfile['correct']\n",
    "    #get reaction times\n",
    "    reaction_time = csvfile['key_resp.rt']\n",
    "    \n",
    "    #Get csv file for every Condition\n",
    "    happy_happy = csvfile[(csvfile['primeEmotion'] == 'happy') & (csvfile['targetEmotion'] == 'happy')]\n",
    "    happy_sad = csvfile[(csvfile['primeEmotion'] == 'happy') & (csvfile['targetEmotion'] == 'sad')]\n",
    "    sad_happy = csvfile[(csvfile['primeEmotion'] == 'sad') & (csvfile['targetEmotion'] == 'happy')]\n",
    "    sad_sad = csvfile[(csvfile['primeEmotion'] == 'sad') & (csvfile['targetEmotion'] == 'happy')]\n",
    "\n",
    "    incongruent = csvfile[csvfile['targetEmotion'] != csvfile['primeEmotion']]\n",
    "    congruent = csvfile[csvfile['targetEmotion'] == csvfile['primeEmotion']]\n",
    "    \n",
    "    #Excecute functions and get one value for each participant\n",
    "    val_rt_happy_happy = rt_happy_happy(csvfile,i)\n",
    "    val_rt_happy_sad = rt_happy_sad(csvfile,i)\n",
    "    val_rt_sad_happy = rt_sad_happy(csvfile,i)\n",
    "    val_rt_sad_sad = rt_sad_sad(csvfile,i)\n",
    "    val_rt_incongruent = rt_incongruent(csvfile,i)\n",
    "    val_rt_congruent = rt_congruent(csvfile,i)\n",
    "\n",
    "    val_rt_incongruent = rt_incongruent(csvfile,i)\n",
    "    val_rt_congruent = rt_congruent(csvfile,i)\n",
    "\n",
    "    val_slider_happy_happy = slider_happy_happy(csvfile,i)\n",
    "    val_slider_happy_sad = slider_happy_sad(csvfile,i)\n",
    "    val_slider_sad_happy = slider_sad_happy(csvfile,i)\n",
    "    val_slider_sad_sad = slider_sad_sad(csvfile,i)\n",
    "\n",
    "    val_slider_incongruent = slider_incongruent(csvfile,i)\n",
    "    val_slider_congruent = slider_congruent(csvfile,i)\n",
    "    \n",
    "    val_participant_ID = i[80:87] #get sub number of participant\n",
    "\n",
    "    val_number_corr_ans = number_corr_ans(csvfile,i)\n",
    "    val_reaction_number = reaction_number(csvfile,i)\n",
    "    val_total_mean_rt = total_mean_rt(csvfile,i)\n",
    "    \n",
    "    #append values to append individual value to one lis.append(val_)\n",
    "    list_rt_happy_happy.append(val_rt_happy_happy)\n",
    "    list_rt_happy_sad.append(val_rt_happy_sad)\n",
    "    list_rt_sad_happy.append(val_rt_sad_happy)\n",
    "    list_rt_sad_sad.append(val_rt_sad_sad)\n",
    "    list_rt_incongruent.append(val_rt_incongruent)\n",
    "    list_rt_congruent.append(val_rt_congruent)\n",
    "    \n",
    "    list_slider_happy_happy.append(val_slider_happy_happy)\n",
    "    list_slider_happy_sad.append(val_slider_happy_sad)\n",
    "    list_slider_sad_happy.append(val_slider_sad_happy)\n",
    "    list_slider_sad_sad.append(val_slider_sad_sad)\n",
    "    list_slider_incongruent.append(val_slider_incongruent)\n",
    "    list_slider_congruent.append(val_slider_congruent)\n",
    "    \n",
    "    list_total_mean_rt.append(val_total_mean_rt)\n",
    "    list_participant_ID.append(val_participant_ID)\n",
    "    list_number_corr_ans.append(val_number_corr_ans)\n",
    "    list_reaction_number.append(val_reaction_number)\n",
    "    \n",
    "    #Create dataframe \n",
    "    rt_data = {'name': list_participant_ID,\n",
    "                     'number of reactions': list_reaction_number,\n",
    "                     'number of correct answers': list_number_corr_ans,\n",
    "                     'total trials': list_total_mean_rt,\n",
    "                     'rt_incongruent': list_rt_incongruent,\n",
    "                     'rt_congruent': list_rt_congruent,\n",
    "                     'rt_happy_happy':list_rt_happy_happy,\n",
    "                     'rt_happy_sad':list_rt_happy_sad,\n",
    "                     'rt_sad_happy':list_rt_sad_happy,\n",
    "                     'rt_sad_sad':list_rt_sad_sad,\n",
    "               \n",
    "                     'slider_incongruent': list_slider_incongruent,\n",
    "                     'slider_congruent': list_slider_congruent,\n",
    "                     'slider_happy_happy':list_slider_happy_happy,\n",
    "                     'slider_happy_sad':list_slider_happy_sad,\n",
    "                     'slider_sad_happy':list_slider_sad_happy,\n",
    "                     'slider_sad_sad':list_slider_sad_sad}\n",
    "    \n",
    "    mean_rt = pd.DataFrame(data=rt_data)\n",
    "    mean_rt = mean_rt.round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in csv data generated by PsychoPy\n",
    "participant = glob.glob('W:/Fmri_Forschung/Allerlei/JuliaS/GitHub/SubliminalVideoPriming/data/behav_data/*.csv') \n",
    "len(participant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists to append values and to store them in the dataframe df with mean reactions\n",
    "list_rt_happy_happy = []\n",
    "list_rt_happy_sad = []\n",
    "list_rt_sad_happy = []\n",
    "list_rt_sad_sad = []\n",
    "\n",
    "list_rt_incongruent = []\n",
    "list_rt_congruent = []\n",
    "\n",
    "list_slider_happy_happy = []\n",
    "list_slider_happy_sad = []\n",
    "list_slider_sad_happy = []\n",
    "list_slider_sad_sad = []\n",
    "\n",
    "list_slider_incongruent = []\n",
    "list_slider_congruent = []\n",
    "\n",
    "list_total_mean_rt= []\n",
    "list_participant_ID = []\n",
    "list_number_corr_ans = []\n",
    "list_reaction_number =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-6142d142bd4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparticipant\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m#read in csv for every participant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mcsvfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m\";\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#delete first two rows for example trials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juhoffmann\\Anaconda3\\envs\\Bids\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juhoffmann\\Anaconda3\\envs\\Bids\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juhoffmann\\Anaconda3\\envs\\Bids\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1702\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1703\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1704\u001b[1;33m                 \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m  \u001b[1;31m# type: ignore[attr-defined]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1705\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1706\u001b[0m                 )\n",
      "\u001b[1;32mc:\\Users\\juhoffmann\\Anaconda3\\envs\\Bids\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m                 \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m                 \u001b[1;31m# destructive to chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juhoffmann\\Anaconda3\\envs\\Bids\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juhoffmann\\Anaconda3\\envs\\Bids\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juhoffmann\\Anaconda3\\envs\\Bids\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juhoffmann\\Anaconda3\\envs\\Bids\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juhoffmann\\Anaconda3\\envs\\Bids\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
     ]
    }
   ],
   "source": [
    "for i in participant:\n",
    "    #read in csv for every participant\n",
    "    csvfile = pd.read_csv(i, sep =\";\")\n",
    "        \n",
    "    #delete first two rows for example trials \n",
    "    csvfile = csvfile.iloc[2:]\n",
    "    #insert index of trials for study part starting with 0\n",
    "    length = len(csvfile)\n",
    "    csvfile.insert(loc=0, column='index', value=np.arange(length))\n",
    "    \n",
    "    #get correct trials\n",
    "    def correctness(csvfile):\n",
    "        if csvfile['corrAnsTar'] == 7 and csvfile['key_resp.keys']== \"7\":\n",
    "            return 1\n",
    "        if csvfile['corrAnsTar'] == 8 and csvfile['key_resp.keys']== \"8\":\n",
    "            return 1\n",
    "        if csvfile['corrAnsTar'] == 9 and csvfile['key_resp.keys']== \"9\":\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    csvfile['correct'] = csvfile.apply(correctness, axis=1)    \n",
    "    \n",
    "     #get correct answers\n",
    "    corr_answers = csvfile['correct']\n",
    "    #get reaction times\n",
    "    reaction_time = csvfile['key_resp.rt']\n",
    "    \n",
    "    #Get csv file for every Condition\n",
    "    happy_happy = csvfile[(csvfile['primeEmotion'] == 'happy') & (csvfile['targetEmotion'] == 'happy')]\n",
    "    happy_sad = csvfile[(csvfile['primeEmotion'] == 'happy') & (csvfile['targetEmotion'] == 'sad')]\n",
    "    sad_happy = csvfile[(csvfile['primeEmotion'] == 'sad') & (csvfile['targetEmotion'] == 'happy')]\n",
    "    sad_sad = csvfile[(csvfile['primeEmotion'] == 'sad') & (csvfile['targetEmotion'] == 'happy')]\n",
    "\n",
    "    incongruent = csvfile[csvfile['targetEmotion'] != csvfile['primeEmotion']]\n",
    "    congruent = csvfile[csvfile['targetEmotion'] == csvfile['primeEmotion']]\n",
    "    \n",
    "    #Excecute functions and get one value for each participant\n",
    "    val_rt_happy_happy = rt_happy_happy(csvfile,i)\n",
    "    val_rt_happy_sad = rt_happy_sad(csvfile,i)\n",
    "    val_rt_sad_happy = rt_sad_happy(csvfile,i)\n",
    "    val_rt_sad_sad = rt_sad_sad(csvfile,i)\n",
    "    val_rt_incongruent = rt_incongruent(csvfile,i)\n",
    "    val_rt_congruent = rt_congruent(csvfile,i)\n",
    "\n",
    "    val_rt_incongruent = rt_incongruent(csvfile,i)\n",
    "    val_rt_congruent = rt_congruent(csvfile,i)\n",
    "\n",
    "    val_slider_happy_happy = slider_happy_happy(csvfile,i)\n",
    "    val_slider_happy_sad = slider_happy_sad(csvfile,i)\n",
    "    val_slider_sad_happy = slider_sad_happy(csvfile,i)\n",
    "    val_slider_sad_sad = slider_sad_sad(csvfile,i)\n",
    "\n",
    "    val_slider_incongruent = slider_incongruent(csvfile,i)\n",
    "    val_slider_congruent = slider_congruent(csvfile,i)\n",
    "    \n",
    "    val_participant_ID = i[80:87]#get sub number of participant\n",
    "    val_number_corr_ans = number_corr_ans(csvfile,i)\n",
    "    val_reaction_number = reaction_number(csvfile,i)\n",
    "    val_total_mean_rt = total_mean_rt(csvfile,i)\n",
    "    \n",
    "    #append values to append individual value to one lis.append(val_)\n",
    "    list_rt_happy_happy.append(val_rt_happy_happy)\n",
    "    list_rt_happy_sad.append(val_rt_happy_sad)\n",
    "    list_rt_sad_happy.append(val_rt_sad_happy)\n",
    "    list_rt_sad_sad.append(val_rt_sad_sad)\n",
    "    list_rt_incongruent.append(val_rt_incongruent)\n",
    "    list_rt_congruent.append(val_rt_congruent)\n",
    "    \n",
    "    list_slider_happy_happy.append(val_slider_happy_happy)\n",
    "    list_slider_happy_sad.append(val_slider_happy_sad)\n",
    "    list_slider_sad_happy.append(val_slider_sad_happy)\n",
    "    list_slider_sad_sad.append(val_slider_sad_sad)\n",
    "    list_slider_incongruent.append(val_slider_incongruent)\n",
    "    list_slider_congruent.append(val_slider_congruent)\n",
    "    \n",
    "    list_total_mean_rt.append(val_total_mean_rt)\n",
    "    list_participant_ID.append(val_participant_ID)\n",
    "    list_number_corr_ans.append(val_number_corr_ans)\n",
    "    list_reaction_number.append(val_reaction_number)\n",
    "    \n",
    "    #Create dataframe \n",
    "    rt_data = {'name': list_participant_ID,\n",
    "                     'number of reactions': list_reaction_number,\n",
    "                     'number of correct answers': list_number_corr_ans,\n",
    "                     'total trials': list_total_mean_rt,\n",
    "                     'rt_incongruent': list_rt_incongruent,\n",
    "                     'rt_congruent': list_rt_congruent,\n",
    "                     'rt_happy_happy':list_rt_happy_happy,\n",
    "                     'rt_happy_sad':list_rt_happy_sad,\n",
    "                     'rt_sad_happy':list_rt_sad_happy,\n",
    "                     'rt_sad_sad':list_rt_sad_sad,\n",
    "               \n",
    "                     'slider_incongruent': list_slider_incongruent,\n",
    "                     'slider_congruent': list_slider_congruent,\n",
    "                     'slider_happy_happy':list_slider_happy_happy,\n",
    "                     'slider_happy_sad':list_slider_happy_sad,\n",
    "                     'slider_sad_happy':list_slider_sad_happy,\n",
    "                     'slider_sad_sad':list_slider_sad_sad}\n",
    "    \n",
    "    mean_rt = pd.DataFrame(data=rt_data)\n",
    "    mean_rt = mean_rt.round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rt.to_csv(r'W:/Fmri_Forschung/Allerlei/JuliaS/GitHub/SubliminalVideoPriming/data/VideoMask_Mean_RT.csv',sep =';', index = True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rt = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bids",
   "language": "python",
   "name": "bids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
